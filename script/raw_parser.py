#
# Flex Challenge Generator 
#

import os
import json
import random
import pprint

ALL_DLOGS = [] # All dialogs

RAW_DAT_PATH = os.path.dirname(os.path.abspath(__file__))+'/../raw/'
RAW_DAT_FILE = RAW_DAT_PATH+'RawFlexData.json'

WITH_PARA_SAMPLE = False # If true, replace orig dialog with paraphrases
NUM_PARA_SAMPLE= 10 # Num examples generated by replacing w/ paraphrases

TRAIN_SET_SZ = 1 # Num of train examples to generate
TEST_SET_SZ = 100 # Num of test examples to generate
PARA_BAG_SZ = 100 # Num of utterances per para bag
RAND_SEED = 7
random.seed(RAND_SEED)

TRAIN_SET = {}
TEST_SET = {}

DEBUG = True

#===============================================================================
#
def combine_all_dialogs(_RAW_DAT_FILE):
	global ALL_DLOGS
	print(_RAW_DAT_FILE)
	with open(_RAW_DAT_FILE) as json_file:
		data = json.load(json_file)

		for batch in data:
			# print('===========================================================')
			# print('Collect Time: ', batch['collectTime'])
			# print('Num Dialogs: ', len(batch['data']))
			ALL_DLOGS = ALL_DLOGS + batch['data']

	print('===========================================================')
	print('Total Num Dialogs: ', len(ALL_DLOGS))
	return

#===============================================================================
#
def partition_train_test_docs():
	global TEST_SET_SZ, RAND_SEED

	num_dlog = len(ALL_DLOGS)
	indices = [i for i in range(num_dlog)]
	random.shuffle(indices)

	tr_sz = num_dlog - TEST_SET_SZ # training set size
	train_idx, test_idx = indices[:tr_sz], indices[tr_sz:]

	print('Num train examples: ',len(train_idx))
	print('Num test examples: ',len(test_idx))

	return train_idx, test_idx

#===============================================================================
#
def generate_train_set(_train_idx):
	global DEBUG

	IS_IN_THE_SET = [] # list of dicts (keeps track of examples already generated)

	#-------------------------------------------------------------
	# without random paraphrase sample (WITH_PARA_SAMPLE False)
	# IS_IN_THE_SET [hash1, hash2]
	# [dialogID, turnID, paraID]

	#-------------------------------------------------------------
	# with random paraphrase sample (WITH_PARA_SAMPLE True)
	# IS_IN_THE_SET
	# [dialogID, turnID, random paraphrase sample

	#-------------------------------------------------------------
	# while number train <= TRAIN_SET_SZ
	# pick random dialog
	# pick random advisor turn
	# pick random set paraphrases
	while len(TRAIN_SET) < TRAIN_SET_SZ:

		# pick random index i from _train_idx
		di = random.choice(_train_idx)

		# get dialog d from ALL_DLOGS[i]
		d = ALL_DLOGS[di]
		dn = d['dialogName']
		pprint.pprint(d['content'])

		# pick random advisor query (aq) from d
		_ais = range(len(d['content']))
		_aq = [ai for ai in _ais if d['content'][ai]['role'] == 'ADVISOR']
		print('_aq',_aq)
		aq = random.choice(_aq)
		print('aq',aq)

		# get prior utterances (pu) up to but excluding aq
		pu = d['content'][0:aq]

		# remove extra information from pu
		for u in pu:
			del u['paraphrases']

		if(DEBUG):
			print('-----------------------------------------------------------')
			print('--- PRIOR UTTERANCES')
			pprint.pprint(pu)

		# get ground truth paraphrase set (gt) for aq
		gt = d['content'][aq]['paraphrases']

		if(DEBUG):
			print('-----------------------------------------------------------')
			print('--- GROUND TRUTH PARAPHRASE SET')
			pprint.pprint(gt)

		# generate bag of paraphrases size PARA_BAG_SZ
		# input: current dialogID

		PARA_BAG = []

		while len(PARA_BAG) < PARA_BAG_SZ:

		# for any dialog with idx in _train_idx other than i
		# repeat the process:
		#	pick random dialog
		#	pick random advisor utterance
		#	pick random number of paraphrases of utterance
		#	add to PARA_BAG, if not already in PARA_BAG
			break

		'''
		Save to IS_IN_THE_SET as JSON string
			{
		 		dn : dialogName, 
		 		aq : oriSenId,
		 		ps : [ (oriSen,paraId) ] # empty if WITH_PARA_SAMPLE is False
		 	}

			dn is the dialogName
			aq is the oriSenId of the advisor query
			ps is a list of (oriSen,paraId) pairs (paraphrase sample)

		'''

		gen_example = 0

		if(gen_example in IS_IN_THE_SET):
			# reloop
			dummy = 0
		else:
			# break
			dummy = 0

		break

	return

#===============================================================================
#
def generate_test_set(_test_idx):

	return

#===============================================================================
#
def get_next_query():

	return

#===============================================================================
#
def get_bag_para():

	return

#===============================================================================
#
def zip_x_y():

	return

#===============================================================================
#
def generate_dataset(_train_doc_i, _test_doc_i):
	if(DEBUG):
		print('-----------------------------------------------------------')
		print('-----------------------------------------------------------')
		print('--- GENERATING DATASET')

	generate_train_set(_train_doc_i)

	return


#===============================================================================
#	Main
#===============================================================================
def main():
	combine_all_dialogs(RAW_DAT_FILE)

	train_doc_i, test_doc_i = partition_train_test_docs()

	generate_dataset(train_doc_i, test_doc_i)

	return


if __name__ == "__main__":
	main()
