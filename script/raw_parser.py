#
# Flex Generator 
#

import os
import json
import random
import pprint

ALL_DLOGS = [] # All dialogs

RAW_DAT_PATH = os.path.dirname(os.path.abspath(__file__))+'/../raw/'
RAW_DAT_FILE = RAW_DAT_PATH+'RawFlexData.json'

WITH_PARA_SAMPLE = False # If true, replace orig dialog with paraphrases
NUM_PARA_SAMPLE= 10 # Num examples generated by replacing w/ paraphrases

TRAIN_SET_SZ = 1 # Num of train examples to generate
TEST_SET_SZ = 100 # Num of test examples to generate
PARA_BAG_SZ = 10 # Num of utterances per para bag
RAND_SEED = 4
random.seed(RAND_SEED)

TRAIN_SET = {}
TEST_SET = {}

DEBUG = True

#===============================================================================
# returns n elements randomly selected from list
# n is also random
def pick_n_randomly(_l):
	_lis = [i for i in range(len(_l))] # indices of list
	n = random.choice(_lis) # randomly select n indices
	random.shuffle(_lis) # random shuffle indices
	return [_l[i] for i in _lis[0:n]] # return list of n random

#===============================================================================
# returns one elements randomly selected from list _l, not equal to _omit
def pick_1_randomly_neq(_l, _omit):
	o = random.choice(_l)
	if (not _omit):
		return o
	while (o == _omit):
		o = random.choice(_l)
	return o

#===============================================================================
# returns list of original sentence and its paraphrases
def paras_plus_one(_turn):
	print('===================================================================')
	pprint.pprint(_turn)
	return _turn['paraphrases'] + [{
				'oriSen':_turn['oriSen'],
				'oriSenId':_turn['oriSenId']}]

#===============================================================================
# 
# _correct is list of correct elements to put in bag 
# _admissible is list of admissible doc indices to ALL_DLOGS
# _curr_doc is index of doc to omit from bag
def fill_bag_size_N(_correct, _curr_doc, _admissible):
	bag = [] + _correct
	while (len(bag) < PARA_BAG_SZ):
		idx = pick_1_randomly_neq(_admissible, _curr_doc) # random dlog idx
		dlog = ALL_DLOGS[idx]['content'] # dlog content
		aq = random_advisor_query(dlog) # get random advisor query
		dp = paras_plus_one(aq) # get paraphrases plus orig query
		dp = pick_n_randomly(dp) # get n random paras
		num2put = min(PARA_BAG_SZ-len(bag),len(dp)) # num to put in bag
		bag = bag + dp[0:num2put]
	return bag

#===============================================================================
# 
def random_advisor_query(_dlog_content):
		_ais = range(len(_dlog_content))
		_aq = [ai for ai in _ais if _dlog_content[ai]['role'] == 'ADVISOR']
		return _dlog_content[pick_1_randomly_neq(_aq, None)]

#===============================================================================
#
def combine_all_dialogs(_RAW_DAT_FILE):
	global ALL_DLOGS
	print(_RAW_DAT_FILE)
	with open(_RAW_DAT_FILE) as json_file:
		data = json.load(json_file)

		for batch in data:
			# print('===========================================================')
			# print('Collect Time: ', batch['collectTime'])
			# print('Num Dialogs: ', len(batch['data']))
			ALL_DLOGS = ALL_DLOGS + batch['data']

	print('===========================================================')
	print('Total Num Dialogs: ', len(ALL_DLOGS))
	return

#===============================================================================
#
def partition_train_test_docs():
	global TEST_SET_SZ, RAND_SEED

	num_dlog = len(ALL_DLOGS)
	indices = [i for i in range(num_dlog)]
	random.shuffle(indices)

	tr_sz = num_dlog - TEST_SET_SZ # training set size
	train_idx, test_idx = indices[:tr_sz], indices[tr_sz:]

	print('Num train examples: ',len(train_idx))
	print('Num test examples: ',len(test_idx))

	return train_idx, test_idx

#===============================================================================
#
def generate_train_set(_train_idx):
	global DEBUG

	IS_IN_THE_SET = [] # list of dicts (keeps track of examples already generated)

	#-------------------------------------------------------------
	# without random paraphrase sample (WITH_PARA_SAMPLE False)
	# IS_IN_THE_SET [hash1, hash2]
	# [dialogID, turnID, paraID]

	#-------------------------------------------------------------
	# with random paraphrase sample (WITH_PARA_SAMPLE True)
	# IS_IN_THE_SET
	# [dialogID, turnID, random paraphrase sample

	#-------------------------------------------------------------
	# while number train <= TRAIN_SET_SZ
	# pick random dialog
	# pick random advisor turn
	# pick random set paraphrases
	while len(TRAIN_SET) < TRAIN_SET_SZ:

		# pick random index i from _train_idx
		di = pick_1_randomly_neq(_train_idx, None)

		# get dialog d from ALL_DLOGS[i]
		d = ALL_DLOGS[di]
		dn = d['dialogName']
		# pprint.pprint(d['content'])

		# pick random advisor query (aq) from d
		_ais = range(len(d['content']))
		_aq = [ai for ai in _ais if d['content'][ai]['role'] == 'ADVISOR']
		print('_aq',_aq)
		aq = random.choice(_aq)

		# get prior utterances (pu) up to but excluding aq
		pu = d['content'][0:aq]

		# FIXME! Q: Omit cases where there are no prior utterances? A: YES

		# remove extra information from pu
		for u in pu:
			del u['paraphrases']

		if(DEBUG):
			print('-----------------------------------------------------------')
			print('--- PRIOR UTTERANCES')
			pprint.pprint(pu)

		# get ground truth paraphrase set (gt) for aq
		paras_plus = paras_plus_one(d['content'][aq])
		gt = pick_n_randomly(paras_plus)

		'''
		ps = d['content'][aq]['paraphrases']
		_pis = [i for i in range(len(ps))] # indices of paras
		n = random.choice(_pis) # randomly select n paras
		random.shuffle(_pis) # random shuffle indices
		gt = [ps[i] for i in _pis[0:n]] # ground truth paras
		'''

		if(DEBUG):
			print('-----------------------------------------------------------')
			print('--- GROUND TRUTH PARAPHRASE SET')
			pprint.pprint(gt)

		# generate bag of paraphrases size PARA_BAG_SZ
		# input: current dialogID
		print('_train_idx',_train_idx)
		print('di',di)
		fill_bag_size_N(gt, di, _train_idx)

		# for any dialog with idx in _train_idx other than i
		# repeat the process:
		#	pick random dialog
		#	pick random advisor utterance
		#	pick random number of paraphrases of utterance
		#	add to PARA_BAG, if not already in PARA_BAG

		'''
		Save to IS_IN_THE_SET as JSON string
			{
		 		dn : dialogName, 
		 		aq : oriSenId,
		 		ps : [ (oriSen,paraId) ] # empty if WITH_PARA_SAMPLE is False
		 	}

			dn is the dialogName
			aq is the oriSenId of the advisor query
			ps is a list of (oriSen,paraId) pairs (paraphrase sample)

		'''

		gen_example = 0

		if(gen_example in IS_IN_THE_SET):
			# reloop
			dummy = 0
		else:
			# break
			dummy = 0

		break

	return

#===============================================================================
#
def generate_test_set(_test_idx):

	return

#===============================================================================
#
def get_next_query():

	return

#===============================================================================
#
def get_bag_para():

	return

#===============================================================================
#
def zip_x_y():

	return

#===============================================================================
#
def generate_dataset(_train_doc_i, _test_doc_i):
	if(DEBUG):
		print('-----------------------------------------------------------')
		print('-----------------------------------------------------------')
		print('--- GENERATING DATASET')

	generate_train_set(_train_doc_i)

	return


#===============================================================================
#	Main
#===============================================================================
def main():
	combine_all_dialogs(RAW_DAT_FILE)

	train_doc_i, test_doc_i = partition_train_test_docs()

	generate_dataset(train_doc_i, test_doc_i)

	return


if __name__ == "__main__":
	main()
